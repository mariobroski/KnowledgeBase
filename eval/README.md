# ðŸ“Š Ewaluacja RAGBench + FinanceBench

## ðŸŽ¯ **Cel**

Kompletny system ewaluacji strategii RAG (Text, Facts, Graph, Hybrid) na benchmarkach RAGBench i FinanceBench z metrykami TRACe i RAGAS.

## ðŸ—ï¸ **Architektura**

```
eval/
â”œâ”€â”€ ingest_ragbench.py      # Importer korpusÃ³w RAGBench
â”œâ”€â”€ ingest_financebench.py  # Importer korpusÃ³w FinanceBench  
â”œâ”€â”€ run_eval.py             # Harness oceniajÄ…cy TRACe + RAGAS
â”œâ”€â”€ generate_report.py      # Generator raportÃ³w i wykresÃ³w
â”œâ”€â”€ run_full_pipeline.py    # PeÅ‚ny pipeline ewaluacji
â”œâ”€â”€ data/                   # Dane korpusÃ³w
â”œâ”€â”€ results/                # Wyniki ewaluacji (CSV, JSON)
â””â”€â”€ reports/                # Raporty i wykresy
```

## ðŸš€ **Szybki start**

### **1. Przygotowanie Å›rodowiska**

```bash
# Uruchom backend
cd backend
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000

# W nowym terminalu
cd eval
```

### **2. Szybki test**

```bash
# Test jednej domeny i polityki
python run_full_pipeline.py --quick FinQA text

# SprawdÅº wyniki
ls results/
ls reports/
```

### **3. PeÅ‚ny pipeline**

```bash
# Wszystkie domeny i polityki
python run_full_pipeline.py --full

# Konkretne domeny i polityki
python run_full_pipeline.py --full FinQA,TAT-QA text,facts,graph
```

### **4. Demonstracja zaawansowanych funkcjonalnoÅ›ci**

```bash
# Uruchom demonstracjÄ™
python demo_advanced_features.py

# SprawdÅº wygenerowane wykresy
ls *.png
```

## ðŸ“‹ **DostÄ™pne domeny**

### **RAGBench**
- **FinQA** - Pytania finansowe z tabelami
- **TAT-QA** - Pytania tabelaryczne
- **TechQA** - Pytania techniczne
- **CUAD** - Pytania prawne
- **EManual** - Pytania z instrukcji

### **FinanceBench**
- **FinanceBench** - Sprawozdania finansowe
- **FinancialQA** - Pytania finansowe
- **FinNLP** - NLP finansowe

## ðŸ”§ **DostÄ™pne polityki**

- **text** - TextRAG (semantic search)
- **facts** - FactRAG (fact-based)
- **graph** - GraphRAG (knowledge graph)
- **hybrid** - HybridRAG (kombinacja)

## ðŸ“Š **Metryki ewaluacji**

### **TRACe (RAGBench)**
- **Relevance** - trafnoÅ›Ä‡ odpowiedzi wzglÄ™dem pytania
- **Utilization** - wykorzystanie kontekstu
- **Adherence** - zgodnoÅ›Ä‡ z kontekstem (faithfulness)
- **Completeness** - kompletnoÅ›Ä‡ wzglÄ™dem ground truth

### **RAGAS**
- **Faithfulness** - zgodnoÅ›Ä‡ odpowiedzi z kontekstem
- **Answer Relevance** - trafnoÅ›Ä‡ odpowiedzi
- **Context Precision** - precyzja kontekstu
- **Context Recall** - recall kontekstu

### **Operacyjne**
- **Latency** - czas odpowiedzi (p50, p95)
- **Tokens** - liczba tokenÃ³w
- **Cost** - koszt ($)

## ðŸ› ï¸ **UÅ¼ycie**

### **Import korpusÃ³w**

```bash
# RAGBench
python ingest_ragbench.py FinQA
python ingest_ragbench.py TAT-QA
python ingest_ragbench.py TechQA

# FinanceBench
python ingest_financebench.py FinanceBench
python ingest_financebench.py FinancialQA
```

### **Ewaluacja**

```bash
# Wszystkie polityki
python run_eval.py FinQA

# Konkretne polityki
python run_eval.py FinQA text,facts,graph
```

### **Raporty**

```bash
# Raport dla domeny
python generate_report.py FinQA

# Zbiorczy raport
python generate_report.py FinQA,TAT-QA,FinanceBench --combined
```

## ðŸ“ˆ **Wyniki**

### **Pliki wynikÃ³w**
- `results/{domain}_results_{timestamp}.csv` - Wyniki ewaluacji
- `results/{domain}_summary_{timestamp}.json` - Podsumowanie

### **Raporty**
- `reports/{domain}_report.json` - Raport domeny
- `reports/{domain}_comparison.csv` - Tabela porÃ³wnawcza
- `reports/{domain}_*.png` - Wykresy

### **Wykresy**
- **TRACe Metrics** - PorÃ³wnanie metryk TRACe
- **RAGAS Metrics** - PorÃ³wnanie metryk RAGAS
- **Latency Comparison** - PorÃ³wnanie latencji
- **Cost Comparison** - PorÃ³wnanie kosztÃ³w
- **Correlation Heatmap** - Heatmapa korelacji

## ðŸ” **PrzykÅ‚adowe wyniki**

### **Tabela porÃ³wnawcza**

| Policy | Relevance | Adherence | Latency (p95) | Cost |
|--------|-----------|-----------|---------------|------|
| text   | 0.85      | 0.78      | 1200ms        | 0.003 |
| facts  | 0.88      | 0.82      | 1500ms        | 0.002 |
| graph  | 0.92      | 0.89      | 2200ms        | 0.001 |
| hybrid | 0.90      | 0.85      | 1800ms        | 0.002 |

### **Wnioski**
- **GraphRAG** osiÄ…ga najlepszÄ… adherence (0.89)
- **GraphRAG** jest najtaÅ„szy (0.001$)
- **GraphRAG** jest 1.8x wolniejszy od TextRAG
- **FactsRAG** balansuje wydajnoÅ›Ä‡ i jakoÅ›Ä‡

## âš™ï¸ **Konfiguracja**

### **Parametry testowe**

```python
# eval/run_eval.py
test_params = {
    "text": {"policy": "text", "top_k": 5, "similarity_threshold": 0.7},
    "facts": {"policy": "facts", "top_k": 5, "fact_confidence_threshold": 0.8},
    "graph": {"policy": "graph", "top_k": 5, "graph_max_depth": 3, "graph_max_paths": 10},
    "hybrid": {"policy": "hybrid", "top_k": 5, "similarity_threshold": 0.7}
}
```

### **Ograniczenia**
- Maksymalnie 100 zapytaÅ„ na domenÄ™ (dla testÃ³w)
- Timeout 30 minut na ewaluacjÄ™ domeny
- Timeout 5 minut na import korpusu

## ðŸ› **RozwiÄ…zywanie problemÃ³w**

### **API nie jest dostÄ™pne**
```bash
# SprawdÅº czy backend dziaÅ‚a
curl http://localhost:8000/health

# Uruchom backend
cd backend
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

### **BÅ‚Ä…d importu korpusu**
```bash
# SprawdÅº logi
python ingest_ragbench.py FinQA 2>&1 | tee import.log

# SprawdÅº dostÄ™pnoÅ›Ä‡ korpusÃ³w
ls data/
```

### **BÅ‚Ä…d ewaluacji**
```bash
# SprawdÅº logi
python run_eval.py FinQA 2>&1 | tee eval.log

# SprawdÅº wyniki
ls results/
```

## ðŸ“š **Dokumentacja**

### **Struktura danych**

```json
{
  "query_id": "finqa_1_1",
  "domain": "FinQA",
  "policy": "text",
  "query": "What was Company XYZ's revenue?",
  "response": "Company XYZ reported revenue of $1.2M",
  "context": {
    "fragments": [
      {"content": "Company XYZ reported revenue of $1.2M in Q3 2023"}
    ]
  },
  "metrics": {
    "relevance": 0.92,
    "utilization": 0.85,
    "adherence": 0.88,
    "completeness": 0.90,
    "faithfulness": 0.87,
    "answer_relevance": 0.91,
    "context_precision": 0.83,
    "context_recall": 0.86,
    "search_time": 150.0,
    "generation_time": 800.0,
    "total_time": 950.0,
    "tokens_used": 120,
    "cost": 0.002
  }
}
```

### **Mapowanie ID**

```json
{
  "finqa_1": {
    "article_id": 123,
    "fragment_ids": [456, 457, 458]
  }
}
```

## ðŸŽ¯ **NastÄ™pne kroki**

1. **Uruchom szybki test** - `python run_full_pipeline.py --quick FinQA text`
2. **SprawdÅº wyniki** - `ls results/` i `ls reports/`
3. **Uruchom peÅ‚ny pipeline** - `python run_full_pipeline.py --full`
4. **Analizuj raporty** - SprawdÅº wykresy i tabele porÃ³wnawcze
5. **PorÃ³wnaj z literaturÄ…** - SprawdÅº czy wyniki sÄ… zgodne z benchmarkami

## ðŸ“ž **Wsparcie**

- **Logi** - SprawdÅº logi w konsoli
- **Pliki** - SprawdÅº pliki w `results/` i `reports/`
- **API** - SprawdÅº status API na `http://localhost:8000/health`
- **Backend** - SprawdÅº logi backendu

---

**ðŸŽ‰ Gotowe do ewaluacji!**
