#!/usr/bin/env python3
"""
Skrypt do aktualizacji artyku≈Ç√≥w - usuniƒôcie artyku≈Ç√≥w o historii Polski
i dodanie artyku≈Ç√≥w zwiƒÖzanych z projektem RAG/AI
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from sqlalchemy.orm import Session
from app.db.database import SessionLocal
from app.db.database_models import Article, Tag, Fragment, article_tag, Fact, Entity, Relation
from datetime import datetime

def clear_database():
    """Czy≈õci bazƒô danych z istniejƒÖcych danych"""
    db = SessionLocal()
    
    try:
        # Usu≈Ñ w odpowiedniej kolejno≈õci ze wzglƒôdu na klucze obce
        db.query(Relation).delete()
        db.query(Fact).delete()
        db.query(Fragment).delete()
        db.execute(article_tag.delete())
        db.query(Article).delete()
        db.query(Tag).delete()
        db.query(Entity).delete()
        
        db.commit()
        print("üóëÔ∏è  Wyczyszczono bazƒô danych")
        
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas czyszczenia bazy: {str(e)}")
        db.rollback()
    finally:
        db.close()

def create_project_articles():
    """Tworzy artyku≈Çy zwiƒÖzane z projektem RAG/AI"""
    db = SessionLocal()
    
    try:
        # Przyk≈Çadowe tagi
        tags_data = [
            "RAG", "AI", "machine learning", "NLP", "retrieval", "generation",
            "embeddings", "vector database", "LLM", "transformers", "BERT",
            "GPT", "semantic search", "knowledge base", "chatbot", "QA system",
            "text processing", "information retrieval", "neural networks", "deep learning"
        ]
        
        # Tworzenie tag√≥w
        tag_objects = {}
        for tag_name in tags_data:
            tag = Tag(name=tag_name)
            db.add(tag)
            tag_objects[tag_name] = tag
        
        db.flush()  # Zapisz tagi, aby uzyskaƒá ID
        
        # Dane artyku≈Ç√≥w zwiƒÖzanych z projektem
        articles_data = [
            {
                "title": "Wprowadzenie do Retrieval-Augmented Generation (RAG)",
                "content": """Retrieval-Augmented Generation (RAG) to zaawansowana technika w dziedzinie sztucznej inteligencji, kt√≥ra ≈ÇƒÖczy mo≈ºliwo≈õci wyszukiwania informacji z generowaniem tekstu. RAG zosta≈Ç opracowany w celu rozwiƒÖzania problem√≥w zwiƒÖzanych z ograniczeniami tradycyjnych modeli jƒôzykowych.

G≈Ç√≥wne komponenty RAG:

1. Retriever (Wyszukiwarka):
- Odpowiada za znajdowanie relevantnych dokument√≥w
- Wykorzystuje embeddingi do reprezentacji tekstu
- Mo≈ºe u≈ºywaƒá r√≥≈ºnych algorytm√≥w wyszukiwania (BM25, dense retrieval)
- Indeksuje bazƒô wiedzy w formie wektorowej

2. Generator:
- Generuje odpowiedzi na podstawie znalezionych dokument√≥w
- Zazwyczaj wykorzystuje modele typu transformer
- ≈ÅƒÖczy kontekst z zapytaniem u≈ºytkownika
- Mo≈ºe byƒá dostrojony do konkretnej domeny

Zalety RAG:
- Dostƒôp do aktualnych informacji
- Redukcja halucynacji modelu
- Mo≈ºliwo≈õƒá weryfikacji ≈∫r√≥de≈Ç
- Elastyczno≈õƒá w aktualizacji wiedzy
- Lepsza kontrola nad generowanymi odpowiedziami

Zastosowania:
- Systemy pyta≈Ñ i odpowiedzi
- Chatboty korporacyjne
- Asystenci badawczy
- Systemy rekomendacji tre≈õci
- Automatyczne streszczanie dokument√≥w

RAG stanowi prze≈Çom w budowaniu inteligentnych system√≥w, kt√≥re mogƒÖ efektywnie wykorzystywaƒá zewnƒôtrzne ≈∫r√≥d≈Ça wiedzy.""",
                "tags": ["RAG", "AI", "retrieval", "generation", "NLP", "knowledge base"]
            },
            {
                "title": "Embeddingi i Wyszukiwanie Semantyczne",
                "content": """Embeddingi to numeryczne reprezentacje tekstu, kt√≥re umo≈ºliwiajƒÖ maszynom zrozumienie znaczenia i kontekstu s≈Ç√≥w, zda≈Ñ czy ca≈Çych dokument√≥w. W systemach RAG odgrywajƒÖ kluczowƒÖ rolƒô w procesie wyszukiwania semantycznego.

Rodzaje embedding√≥w:

1. Word Embeddings:
- Word2Vec: Wykorzystuje kontekst s≈Ç√≥w do tworzenia reprezentacji
- GloVe: ≈ÅƒÖczy statystyki globalne i lokalne
- FastText: Uwzglƒôdnia strukturƒô morfologicznƒÖ s≈Ç√≥w

2. Sentence Embeddings:
- BERT: Bidirectional Encoder Representations from Transformers
- Sentence-BERT: Zoptymalizowany do reprezentacji zda≈Ñ
- Universal Sentence Encoder: Model Google do embedding√≥w zda≈Ñ

3. Document Embeddings:
- Doc2Vec: Rozszerzenie Word2Vec na dokumenty
- BERT-based: Wykorzystanie BERT do reprezentacji dokument√≥w
- Transformer-based: Nowoczesne modele transformer

Wyszukiwanie semantyczne:

Proces wyszukiwania:
1. Konwersja zapytania na embedding
2. Obliczenie podobie≈Ñstwa z dokumentami w bazie
3. Ranking wynik√≥w wed≈Çug podobie≈Ñstwa
4. Zwr√≥cenie najbardziej relevantnych dokument√≥w

Metryki podobie≈Ñstwa:
- Cosine similarity: Najczƒô≈õciej u≈ºywana
- Euclidean distance: Odleg≈Ço≈õƒá euklidesowa
- Dot product: Iloczyn skalarny

Bazy danych wektorowych:
- Pinecone: ZarzƒÖdzana us≈Çuga w chmurze
- Weaviate: Open-source z GraphQL
- Chroma: Lekka baza dla aplikacji AI
- FAISS: Biblioteka Facebook do szybkiego wyszukiwania

Optymalizacja:
- Approximate Nearest Neighbor (ANN)
- Hierarchical Navigable Small World (HNSW)
- Locality-Sensitive Hashing (LSH)

Embeddingi rewolucjonizujƒÖ spos√≥b, w jaki maszyny rozumiejƒÖ i przetwarzajƒÖ jƒôzyk naturalny.""",
                "tags": ["embeddings", "semantic search", "BERT", "vector database", "NLP", "similarity"]
            },
            {
                "title": "Architektura System√≥w RAG",
                "content": """Projektowanie efektywnej architektury systemu RAG wymaga przemy≈õlanego podej≈õcia do integracji komponent√≥w wyszukiwania i generowania. Nowoczesne systemy RAG sk≈ÇadajƒÖ siƒô z kilku kluczowych warstw.

Warstwy architektury RAG:

1. Warstwa danych:
- ≈πr√≥d≈Ça danych (dokumenty, bazy wiedzy, API)
- Preprocessing i czyszczenie danych
- Segmentacja dokument√≥w na fragmenty
- Metadane i indeksowanie

2. Warstwa embedding√≥w:
- Model embedding√≥w (BERT, Sentence-BERT, OpenAI)
- Baza danych wektorowych
- Indeksowanie i aktualizacja
- Optymalizacja wyszukiwania

3. Warstwa wyszukiwania:
- Query processing i rozszerzanie zapyta≈Ñ
- Ranking i filtrowanie wynik√≥w
- Hybrydowe wyszukiwanie (dense + sparse)
- Kontekst i personalizacja

4. Warstwa generowania:
- Model jƒôzykowy (GPT, T5, BART)
- Prompt engineering i templating
- Kontrola jako≈õci odpowiedzi
- Post-processing i formatowanie

5. Warstwa aplikacji:
- API i interfejsy u≈ºytkownika
- ZarzƒÖdzanie sesjami
- Monitoring i logowanie
- Bezpiecze≈Ñstwo i autoryzacja

Wzorce architektoniczne:

1. Pipeline RAG:
- Sekwencyjne przetwarzanie
- Prosty w implementacji
- Ograniczona elastyczno≈õƒá

2. Modular RAG:
- Komponenty wymienne
- ≈Åatwo≈õƒá testowania
- Skalowalna architektura

3. Adaptive RAG:
- Dynamiczny wyb√≥r strategii
- Optymalizacja w czasie rzeczywistym
- Uczenie siƒô z feedbacku

Najlepsze praktyki:
- Monitoring wydajno≈õci i jako≈õci
- A/B testing r√≥≈ºnych konfiguracji
- Caching czƒôsto u≈ºywanych wynik√≥w
- Graceful degradation przy awariach
- Continuous integration/deployment

Wyzwania techniczne:
- Latencja vs. jako≈õƒá wynik√≥w
- Skalowanie z rosnƒÖcƒÖ bazƒÖ wiedzy
- Konsystencja i aktualno≈õƒá danych
- Bezpiecze≈Ñstwo i prywatno≈õƒá

Dobrze zaprojektowana architektura RAG jest kluczem do sukcesu systemu AI.""",
                "tags": ["RAG", "architecture", "system design", "AI", "scalability", "performance"]
            },
            {
                "title": "Modele Jƒôzykowe w Systemach RAG",
                "content": """Modele jƒôzykowe stanowiƒÖ serce system√≥w RAG, odpowiadajƒÖc za generowanie naturalnych i sp√≥jnych odpowiedzi na podstawie wyszukanych informacji. Wyb√≥r odpowiedniego modelu ma kluczowy wp≈Çyw na jako≈õƒá ca≈Çego systemu.

Typy modeli jƒôzykowych:

1. Autoregressive Models:
- GPT (Generative Pre-trained Transformer)
- GPT-2, GPT-3, GPT-4: Ewolucja mo≈ºliwo≈õci
- Generowanie tekstu token po token
- Doskona≈Çe w zadaniach generatywnych

2. Encoder-Decoder Models:
- T5 (Text-to-Text Transfer Transformer)
- BART (Bidirectional and Auto-Regressive Transformers)
- Uniwersalne w r√≥≈ºnych zadaniach NLP
- Efektywne w kondensacji informacji

3. Encoder-Only Models:
- BERT i jego warianty
- G≈Ç√≥wnie do zada≈Ñ rozumienia tekstu
- Wykorzystywane w komponencie retrieval

Kluczowe charakterystyki:

Rozmiar modelu:
- Small (< 1B parametr√≥w): Szybkie, ograniczone mo≈ºliwo≈õci
- Medium (1B-10B): Balans miƒôdzy wydajno≈õciƒÖ a jako≈õciƒÖ
- Large (10B-100B): Wysoka jako≈õƒá, wymagajƒÖ wiƒôcej zasob√≥w
- Very Large (100B+): Najlepsza jako≈õƒá, kosztowne w utrzymaniu

Fine-tuning:
- Domain adaptation: Dostrojenie do konkretnej dziedziny
- Task-specific tuning: Optymalizacja pod konkretne zadanie
- Few-shot learning: Uczenie z ma≈ÇƒÖ ilo≈õciƒÖ przyk≈Çad√≥w
- In-context learning: Uczenie w kontek≈õcie zapytania

Prompt Engineering:
- System prompts: Instrukcje dla modelu
- Few-shot examples: Przyk≈Çady w prompcie
- Chain-of-thought: Prowadzenie rozumowania
- Template design: Strukturyzacja prompt√≥w

Optymalizacja wydajno≈õci:
- Model quantization: Redukcja precyzji
- Knowledge distillation: Transfer wiedzy do mniejszego modelu
- Caching: Przechowywanie czƒôstych odpowiedzi
- Batching: Grupowanie zapyta≈Ñ

Ewaluacja jako≈õci:
- BLEU, ROUGE: Metryki podobie≈Ñstwa
- Perplexity: Miara niepewno≈õci modelu
- Human evaluation: Ocena przez ludzi
- Task-specific metrics: Metryki dedykowane

Wyzwania:
- Hallucination: Generowanie nieprawdziwych informacji
- Bias: Uprzedzenia w danych treningowych
- Consistency: Sp√≥jno≈õƒá odpowiedzi
- Factual accuracy: Dok≈Çadno≈õƒá faktyczna

Przysz≈Ço≈õƒá modeli w RAG:
- Multimodal models: Obs≈Çuga tekstu, obraz√≥w, audio
- Retrieval-augmented pre-training: Integracja retrieval w pre-trainingu
- Adaptive models: Modele dostosowujƒÖce siƒô do kontekstu
- Efficient architectures: Nowe architektury zoptymalizowane pod RAG

Wyb√≥r odpowiedniego modelu jƒôzykowego jest kluczowy dla sukcesu systemu RAG.""",
                "tags": ["LLM", "GPT", "BERT", "transformers", "fine-tuning", "prompt engineering"]
            },
            {
                "title": "Ewaluacja i Metryki System√≥w RAG",
                "content": """Ewaluacja system√≥w RAG jest kompleksowym procesem, kt√≥ry wymaga oceny zar√≥wno komponentu wyszukiwania, jak i generowania. W≈Ça≈õciwe metryki pozwalajƒÖ na obiektywnƒÖ ocenƒô wydajno≈õci i jako≈õci systemu.

Metryki komponentu Retrieval:

1. Precision i Recall:
- Precision: Odsetek relevantnych dokument√≥w w≈õr√≥d zwr√≥conych
- Recall: Odsetek relevantnych dokument√≥w znalezionych
- F1-score: Harmoniczna ≈õrednia precision i recall

2. Ranking Metrics:
- Mean Average Precision (MAP): ≈örednia precyzja dla r√≥≈ºnych poziom√≥w recall
- Normalized Discounted Cumulative Gain (NDCG): Uwzglƒôdnia pozycjƒô w rankingu
- Mean Reciprocal Rank (MRR): ≈örednia odwrotno≈õƒá pozycji pierwszego relevantnego wyniku

3. Coverage Metrics:
- Document coverage: Procent dokument√≥w w bazie, kt√≥re sƒÖ wyszukiwane
- Query coverage: Procent zapyta≈Ñ, dla kt√≥rych system znajduje odpowiedzi

Metryki komponentu Generation:

1. Automatic Metrics:
- BLEU: Podobie≈Ñstwo n-gram√≥w z referencjƒÖ
- ROUGE: Overlap z tekstem referencyjnym
- METEOR: Uwzglƒôdnia synonimy i parafrazowanie
- BERTScore: Podobie≈Ñstwo semantyczne u≈ºywajƒÖc BERT

2. Semantic Metrics:
- Semantic similarity: Podobie≈Ñstwo semantyczne odpowiedzi
- Factual accuracy: Dok≈Çadno≈õƒá faktyczna informacji
- Consistency: Sp√≥jno≈õƒá odpowiedzi na podobne pytania

3. Quality Metrics:
- Fluency: P≈Çynno≈õƒá i naturalno≈õƒá tekstu
- Coherence: Sp√≥jno≈õƒá logiczna odpowiedzi
- Relevance: Trafno≈õƒá odpowiedzi wzglƒôdem pytania

Metryki end-to-end:

1. Task-specific Metrics:
- Exact Match (EM): Dok≈Çadne dopasowanie odpowiedzi
- F1 na poziomie token√≥w: Overlap token√≥w z referencjƒÖ
- Answer accuracy: Poprawno≈õƒá odpowiedzi w zadaniach QA

2. User Experience Metrics:
- Response time: Czas odpowiedzi systemu
- User satisfaction: Zadowolenie u≈ºytkownik√≥w
- Task completion rate: Wska≈∫nik uko≈Ñczenia zada≈Ñ

Human Evaluation:

1. Relevance Assessment:
- Czy odpowied≈∫ jest relevantna do pytania?
- Skala 1-5 lub binary (tak/nie)

2. Factual Accuracy:
- Czy informacje w odpowiedzi sƒÖ prawdziwe?
- Weryfikacja z wiarygodnymi ≈∫r√≥d≈Çami

3. Completeness:
- Czy odpowied≈∫ jest kompletna?
- Czy zawiera wszystkie istotne informacje?

4. Clarity and Readability:
- Czy odpowied≈∫ jest jasna i zrozumia≈Ça?
- Ocena stylu i struktury tekstu

Automated Evaluation Frameworks:

1. RAGAS (RAG Assessment):
- Framework do automatycznej ewaluacji RAG
- Metryki: faithfulness, answer relevancy, context precision

2. TruthfulQA:
- Benchmark do oceny prawdziwo≈õci odpowiedzi
- Fokus na unikanie halucynacji

3. Natural Questions:
- Dataset z naturalnymi pytaniami
- Ewaluacja w realistic scenarios

Best Practices:

1. Multi-dimensional Evaluation:
- Nie polegaj tylko na jednej metryce
- Kombinuj automatic i human evaluation
- Uwzglƒôdnij r√≥≈ºne aspekty jako≈õci

2. Continuous Monitoring:
- Regularnie monitoruj wydajno≈õƒá w produkcji
- Ustaw alerty dla spadk√≥w jako≈õci
- Zbieraj feedback od u≈ºytkownik√≥w

3. A/B Testing:
- Testuj r√≥≈ºne konfiguracje systemu
- Por√≥wnuj metryki miƒôdzy wersjami
- Podejmuj decyzje oparte na danych

Ewaluacja jest kluczowa dla rozwoju i utrzymania wysokiej jako≈õci system√≥w RAG.""",
                "tags": ["evaluation", "metrics", "RAG", "quality assessment", "benchmarking", "testing"]
            }
        ]
        
        # Tworzenie artyku≈Ç√≥w
        for i, article_data in enumerate(articles_data, 1):
            article = Article(
                title=article_data["title"],
                file_path=f"rag_article_{i}.txt",
                file_type="text/plain",
                status="zindeksowany",
                version=1,
                created_at=datetime.utcnow(),
                updated_at=datetime.utcnow(),
                created_by="system"
            )
            
            db.add(article)
            db.flush()  # Zapisz artyku≈Ç, aby uzyskaƒá ID
            
            # Dodaj tagi do artyku≈Çu
            for tag_name in article_data["tags"]:
                if tag_name in tag_objects:
                    article.tags.append(tag_objects[tag_name])
            
            # Utw√≥rz fragment z zawarto≈õciƒÖ
            fragment = Fragment(
                article_id=article.id,
                content=article_data["content"],
                start_position=0,
                end_position=len(article_data["content"])
            )
            db.add(fragment)
            
            print(f"‚úÖ Utworzono artyku≈Ç: {article.title}")
        
        db.commit()
        print(f"\nüéâ Pomy≈õlnie utworzono {len(articles_data)} artyku≈Ç√≥w o RAG/AI!")
        
    except Exception as e:
        print(f"‚ùå B≈ÇƒÖd podczas tworzenia artyku≈Ç√≥w: {str(e)}")
        db.rollback()
    finally:
        db.close()

if __name__ == "__main__":
    print("üîÑ Aktualizacja artyku≈Ç√≥w - usuniƒôcie historii Polski i dodanie artyku≈Ç√≥w o RAG/AI")
    print("=" * 80)
    
    clear_database()
    create_project_articles()
    
    print("‚ú® Gotowe! System zawiera teraz artyku≈Çy zwiƒÖzane z projektem RAG/AI.")